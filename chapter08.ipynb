{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMJtvpxJTnqcHhceC8P8Fhf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **8. Bevezetés a gépi látás mélytanulásába**\n","\n","Ez a fejezet ezekkel foglalkozik:\n","* A konvolúciós neurális hálózatok (convnet - CNN) megértése\n","* Adatbővítés használata a túlillesztés csökkentésére\n","* Előképzett convnet használata a jellemzők kinyeréséhez\n","* Előképzett convnet finomhangolása\n","\n","A gépi látás (CV = Computer Vision) a mély tanulás legkorábbi és legnagyobb sikertörténete. Minden nap kapcsolatba kerülünk a mély-látó modellekkel – a Google Fotókon, a Google képkeresőn, a YouTube-on, a kameraalkalmazások videószűrőin, az OCR-szoftveren és még sok máson keresztül. Ezek a modellek az önvezetés, a robotika, a mesterséges intelligencia által támogatott orvosi diagnosztika, az autonóm kiskereskedelmi pénztárrendszerek és még az önálló mezőgazdálkodás terén folyó kutatások középpontjában is ott állnak.\n","\n","A gépi látás az a problémakör, amely a mély tanulás kezdeti térnyeréséhez vezetett 2011 és 2015 között. A *konvolúciós neurális hálózatoknak* (CNN) nevezett mélytanulási modell ekkortájt kezdett figyelemreméltóan jó eredményeket elérni a képosztályozási versenyeken, először Dan Ciresan nyert két rétegversenyen (az ICDAR 2011 kínai karakterfelismerő verseny és az IJCNN 2011 német közlekedési táblák felismerési versenye), majd különösen 2012 őszén, amikor Hinton csoportja megnyerte a nagy horderejű ImageNet nagyszabású vizuális felismerési kihívását. Gyorsan sok ígéretesebb eredmény kezdett felbukkanni más gépi látási feladatokban is.\n","\n","Érdekes módon ezek a korai sikerek nem voltak elégségesek ahhoz, hogy a mély tanulást akkoriban általánossá tegyék – ez néhány évbe telt. A gépi látást kutató közösség már sok évet eltöltött azzal, hogy neurális hálózatokon kívüli más módszerekbe fektessen be, és nem volt egészen készen arra, hogy lemondjon róluk, csak azért, mert egy új gyerek jött a háztömbbe. 2013-ban és 2014-ben sok vezető gépi látást kutató még mindig heves szkepticizmussal viseltetett a mély tanulással kapcsolatban. Csak 2016-ban vált végül dominánssá. Emlékszem, 2014 februárjában buzdítottam egy volt professzoromat, hogy forduljon a mély tanulás felé. – \"Ez a következő nagy dolog!\" - ezt mondtam. „Nos, talán ez csak egy hóbort” – válaszolta. 2016-ra az egész laborja mélytanulást végzett. Nem lehet megállítani egy ötletet, amelynek eljött az ideje.\n","\n","Ez a fejezet bemutatja a konvolúciós neurális hálózatokat, más néven *convnet*-eket, a mély tanulási modell azon típusát, amelyet ma már szinte általánosan használnak a gépi látási alkalmazásokban. Megtanulhatja a convnet alkalmazását képbesorolási problémákra – különösen azokra, amelyekkel kis betanítási adatkészlet jár, és amelyek a leggyakoribb felhasználási esetek, ha ön nem egy nagy technológiai vállalat."],"metadata":{"id":"2E6OsU75CAo_"}},{"cell_type":"markdown","source":["## 8.1 Bevezetés a convnetbe\n","\n","Hamarosan belemerülünk abba az elméletbe, hogy mik azok a convnet-ek, és miért olyan sikeresek a gépi látási feladatokban. Először azonban vessünk egy gyakorlati pillantást egy egyszerű convnet példára, amely az MNIST számjegyeket osztályozza. Ezt a feladatot a 2. fejezetben egy sűrűn összekötött hálózat segítségével végeztük el (a teszt pontossága akkor 97,8% volt). Annak ellenére, hogy a convnet alapszintű lesz, a pontossága teljesen legyőzi a 2. fejezetből származó, sűrűn összekötött modellünket.\n","\n","A következő lista bemutatja, hogyan néz ki egy alapvető convnet. Ez egy halom `Conv2D` és `MaxPooling2D` réteg. Egy percen belül látni fogja, hogy pontosan mit csinálnak. A modellt az előző fejezetben bemutatott Funkcionális API segítségével készítjük el.\n","\n","**8.1 lista: Egy kis convnet példányosítása**"],"metadata":{"id":"AYKq_h7VVSJ-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0F6CiOTB22e"},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","inputs = keras.Input(shape=(28, 28, 1))\n","x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Flatten()(x)\n","outputs = layers.Dense(10, activation=\"softmax\")(x)\n","model = keras.Model(inputs=inputs, outputs=outputs)"]},{"cell_type":"markdown","source":["Fontos, hogy a convnet az alakzat bemeneti tenzorait veszi fel `(image_height, image_width, image_channels)`, a kötegdimenzió nélkül. Ebben az esetben a convnet-et úgy állítjuk be, hogy a `(28, 28, 1)` méretű bemeneteket dolgozza fel, ami az MNIST képek formátuma.\n","\n","Mutassuk meg a convnetünk architektúráját.\n","\n","**8.2 lista: A modell összegzésének megjelenítése**\n","\n","```\n",">>> model.summary()\n","Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #\n","=================================================================\n","input_1 (InputLayer)         [(None, 28, 28, 1)]       0\n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 26, 26, 32)        320\n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0\n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496\n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0\n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856\n","_________________________________________________________________\n","flatten (Flatten)            (None, 1152)              0\n","_________________________________________________________________\n","dense (Dense)                (None, 10)                11530\n","=================================================================\n","Total params: 104,202\n","Trainable params: 104,202\n","Non-trainable params: 0\n","_________________________________________________________________\n","```"],"metadata":{"id":"_p6pLz0sfKUq"}},{"cell_type":"markdown","source":["Látható, hogy minden `Conv2D` és `MaxPooling2D` réteg kimenete egy `(height, width, channels)` alakú harmadrendű tenzor. A szélesség és magasság méretek általában csökkennek, ahogy mélyebbre megyünk a modellben. A csatornák számát a `Conv2D` rétegeknek átadott első argumentum (32, 64 vagy 128) szabályozza.\n","\n","Az utolsó `Conv2D` réteg után a (3, 3, 128) alakú kimenetet kapjuk – egy 128 csatornából álló 3 × 3-as jellemzőtérképet. A következő lépés ennek a kimenetnek a betáplálása egy sűrűn összekapcsolt osztályozóba, mint amilyeneket már ismerünk: egy halom `Dense` réteget. Ezek az osztályozók vektorokat dolgoznak fel, amelyek 1D-sek, míg az aktuális kimenet egy harmadrendű tenzor. A rés áthidalása érdekében a 3D kimeneteket 1D-re simítjuk egy `Flatten` réteggel, mielőtt hozzáadnánk a `Dense` rétegeket.\n","\n","Végül 10 utas osztályozást végzünk, így az utolsó rétegünk 10 kimenettel és softmax aktiválással rendelkezik.\n","\n","Most pedig tanítsuk be a convnetet az MNIST számjegyekre. A 2. fejezetben található MNIST-példa kódjának nagy részét újra felhasználjuk. Mivel 10-utas osztályozást végzünk softmax kimenettel, a kategorikus keresztentrópia veszteséget fogjuk alkalmazni, és mivel a címkéink egész számok, a ritka változatát fogjuk használni, a `sparse_categorical_crossentropy`-t.\n","\n","**8.3 lista: A convnet betanítása MNIST képeken**"],"metadata":{"id":"MrawOcIvhmZD"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","train_images = train_images.reshape((60000, 28, 28, 1))\n","train_images = train_images.astype(\"float32\") / 255\n","test_images = test_images.reshape((10000, 28, 28, 1))\n","test_images = test_images.astype(\"float32\") / 255\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.fit(train_images, train_labels, epochs=5, batch_size=64)"],"metadata":{"id":"mml3z8trnL1h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Értékeljük a modellt a tesztadatok alapján.\n","\n","**8.4 lista: A convnet kiértékelése**"],"metadata":{"id":"Q9omF4iZneo_"}},{"cell_type":"code","source":[">>> test_loss, test_acc = model.evaluate(test_images, test_labels)\n",">>> print(f\"Test accuracy: {test_acc:.3f}\")\n","Test accuracy: 0.991"],"metadata":{"id":"INgXHdLEoTdi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Míg a 2. fejezetben található sűrűn összekapcsolt modell tesztpontossága 97,8%, addig az alap convnet tesztpontossága 99,1%: a hibaarányt körülbelül 60%-kal csökkentettük (relatív). Nem rossz!\n","\n","De miért működik olyan jól ez az egyszerű convnet egy sűrűn összekapcsolt modellhez képest? Ennek megválaszolásához nézzük meg, mit csinál a `Conv2D` és a `MaxPooling2D` réteg."],"metadata":{"id":"L2JlrfosoeSp"}},{"cell_type":"markdown","source":["###8.1.1 A konvolúció művelet\n","\n","Az alapvető különbség a sűrűn összefüggő réteg és a konvolúciós réteg között a következő: a `Dense` rétegek globális mintákat tanulnak meg bemeneti jellemzőterükben (például egy MNIST számjegy esetén az összes képpontot magában foglaló mintákat), míg a konvolúciós rétegek helyi mintákat tanulnak meg – ebben az esetben a bemenetek kis 2D-s ablakaiban található képeket, mintákat (lásd 8.1. ábra). Az előző példában ezek az ablakok mind 3 × 3 méretűek voltak."],"metadata":{"id":"KrAGfHkyppHE"}},{"cell_type":"markdown","source":["![](figs/8.1_.jpg)\n","\n","**8.1. ábra:** A képek helyi mintákra bonthatók, például élekre, textúrákra stb."],"metadata":{"id":"M5ws7sBErXZt"}}]}